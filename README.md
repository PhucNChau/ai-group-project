# Introduction
## Datasets
Basic datasets are selected because of the limited of computing power of personal machine.
- CIFAR10
- MNIST

## Optimization methods for DL
Popular optimation methods are selected as follows:
- SGD
- Adam
- AdaMax
- Select an algorithm to build it and compare with other built-in optimizers: Adam - Link to the paper: [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)

## Todo list
1. Build models
    - [x] CNN_1: 3 convolutional and 2 FC layers
    - [x] CAE_1: convolutional autoencoder
2. Train, test, print comparison results for 4 architectures in 2 datasets
    - [x] CNN_1 for CIFAR10
    - [x] CNN_1 for MNIST
    - [x] CAE_1 for CIFAR10
    - [x] CAE_1 for MNIST
    - Notes: Each todo is performed in corresponding file and all optimization methods are compared in 4 files.